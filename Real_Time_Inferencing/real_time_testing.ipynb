{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ap = argparse.ArgumentParser()\n",
    "args = {\n",
    "        \"config\": './yolov3-tiny.cfg',\n",
    "        \"weights\": './yolov3-tiny_best_1.weights',\n",
    "        \"classes\": './object.names'\n",
    "        }\n",
    "#args = ap.parse_args()\n",
    "\n",
    "\n",
    "# Get names of output layers, output for YOLOv3 is ['yolo_16', 'yolo_23']\n",
    "def getOutputsNames(net):\n",
    "    layersNames = net.getLayerNames()\n",
    "    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "\n",
    "# Darw a rectangle surrounding the object and its class name \n",
    "def draw_pred(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "\n",
    "    label = str(classes[class_id])\n",
    "    color = COLORS[class_id]\n",
    "\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Feb  7 12:43:04 2020\n",
    "\n",
    "@author: IN0193\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from connector_api import cameraConnector\n",
    "from classify import classify\n",
    "\n",
    "class CaptureRate:\n",
    "    \n",
    "    def __init__(self, path_config_file, path_weights_file, path_labels_file, video_source = 0, \n",
    "                 cap_rate = 4, patience = 30, thresh = 2):\n",
    "        \n",
    "        self.path_config_file = path_config_file\n",
    "        self.path_weights_file = path_weights_file\n",
    "        self.path_labels_file = path_labels_file\n",
    "        self.video_source = video_source                # Default is for the webcam\n",
    "        self.cap_rate = cap_rate                        # Number of frames per second to be captured\n",
    "        \n",
    "        # Patience and Thresholding\n",
    "        self.patience = patience\n",
    "        self.thresh = thresh\n",
    "        \n",
    "        # Initial state of flags \n",
    "        self.flag_patience = True\n",
    "        self.flag_thresh = True\n",
    "        \n",
    "    def load_network(self):\n",
    "        # Read YOLO cfg file and weights file\n",
    "        net = cv2.dnn.readNetFromDarknet(self.path_config_file, self.path_weights_file)\n",
    "        print('[INFO] Network is now loaded...')\n",
    "        return (net)\n",
    "    \n",
    "    \n",
    "    def load_classes(self):\n",
    "                \n",
    "        # List of classes from the text file\n",
    "        classes = open(self.path_labels_file).read().strip().split('\\n')\n",
    "        print('[INFO] Classes initialized...')\n",
    "        return classes\n",
    "    \n",
    "    \n",
    "    def connector_api(self):\n",
    "        \n",
    "        msg = cameraConnector()\n",
    "        print('[INFO] Camera Loaded...')\n",
    "        cap , fps = msg.directConnector()\n",
    "        return cap\n",
    "        \n",
    "             \n",
    "    def main_run(self):\n",
    "        net = self.load_network()\n",
    "        classes = self.load_classes()\n",
    "         \n",
    "        # Get the layers names and select the output layers out of them\n",
    "        layer_names = net.getLayerNames()\n",
    "        outputlayers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        \n",
    "        # Initialize the colours of the bounding boxes\n",
    "        colors= np.random.uniform(0,255,size=(len(classes),3))\n",
    "        \n",
    "        #loading capturing frames from webcam\n",
    "        \n",
    "        \n",
    "        #########################################\n",
    "        #Getting the frame per second of the feed\n",
    "        #########################################\n",
    "        # self.frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        # starting_time= time.time()\n",
    "        # frame_id = 0\n",
    "        \n",
    "        frame_counter = 1        \n",
    "        cap = self.connector_api()\n",
    "        self.frame_rate = 20\n",
    "        while True:\n",
    "            \n",
    "            \n",
    "            \n",
    "            print('Frame ID: {}'.format(frame_counter))\n",
    "            print('[INFO] Entered Loop..')\n",
    "            grabbed ,frame = cap.read()\n",
    "            # cv2.imshow('frame',frame)\n",
    "            \n",
    "            # if cv2.waitKey(1) == ord('q'):\n",
    "            #     cap.release()\n",
    "            #     cv2.destroyAllWindows()\n",
    "            #     break\n",
    "            ###########################################################\n",
    "            # Set the condition for skipping frames from the video feed\n",
    "            ###########################################################\n",
    "            \n",
    "            condition = int(self.frame_rate // self.cap_rate)\n",
    "            if (frame_counter == condition):\n",
    "                \n",
    "                # grabbed ,frame = cap.read()\n",
    "                    \n",
    "                if grabbed:\n",
    "                    print('[INFO] New Frame Grabbed...')\n",
    "            \n",
    "                # Get frame height, width, channels\n",
    "                height,width,channels = frame.shape\n",
    "                \n",
    "                # Blob from the image\n",
    "                blob = cv2.dnn.blobFromImage(frame,0.00392,(416,416),(0,0,0),True,crop=False)\n",
    "                \n",
    "                # Set input to the network\n",
    "                net.setInput(blob)\n",
    "                \n",
    "                # Set the input through all the output layers and get output\n",
    "                outs = net.forward(outputlayers)\n",
    "                \n",
    "                class_ids=[]\n",
    "                confidences=[]\n",
    "                boxes=[]\n",
    "                \n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        \n",
    "                        # Detect the objects with confidences more than mentioned input\n",
    "                        if confidence > 0.3:\n",
    "                            \n",
    "                            center_x= int(detection[0]*width)\n",
    "                            center_y= int(detection[1]*height)                            \n",
    "                            w = int(detection[2]*width)\n",
    "                            h = int(detection[3]*height)\n",
    "                            \n",
    "                            x=int(center_x - w/2)\n",
    "                            y=int(center_y - h/2)\n",
    "                            \n",
    "                            boxes.append([x,y,w,h]) #put all rectangle areas\n",
    "                            confidences.append(float(confidence)) #how confidence was that object detected and show that percentage\n",
    "                            class_ids.append(class_id) #name of the object tha was detected\n",
    "                \n",
    "                # Non Max Supression of the detected objects, with input as confidence score and \n",
    "                # threshold values\n",
    "                indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.65 ,0.4)\n",
    "                \n",
    "                for i in range(len(boxes)):\n",
    "                    if i in indexes:\n",
    "                        x,y,w,h = boxes[i]\n",
    "                        label = str(classes[class_ids[i]])\n",
    "                        if label == \"person\" and x>0 and y>0 and h>80 and w>20:\n",
    "                            image = frame[y:y+h, x:x+w]\n",
    "                            print(image.shape, y,y+h, x,w+x)\n",
    "                            x1, y1, w1, h1, label, confidence = classify(image)\n",
    "                            print( x,y,w,h, label,confidence)\n",
    "#                             confidence= confidences[i]\n",
    "#                             color = colors[class_ids[i]]\n",
    "                            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,255,255),1)\n",
    "                            cv2.putText(frame,str(label) +\" \"+str(round(confidence,2)),(x,y+30),font,1,(255,255,255),2)\n",
    "                        ##################################################\n",
    "                        #Condition for setting up PATIENCE and THRSHOLDING   \n",
    "                        ##################################################\n",
    "                        \n",
    "#                         if (label == 'person'):\n",
    "                            \n",
    "#                             if (self.flag_thresh == True):\n",
    "#                                 ini_thresh_frame_counter = 1\n",
    "#                                 final_thresh_frame_counter = 0\n",
    "#                                 self.flag_thresh = False\n",
    "                            \n",
    "#                             final_thresh_frame_counter += 1\n",
    "#                             thresh_difference = int(final_thresh_frame_counter - ini_thresh_frame_counter)\n",
    "                \n",
    "#                             if (thresh_difference >= (self.thresh * self.cap_rate)):\n",
    "                                \n",
    "#                                 if (self.flag_patience == True):\n",
    "#                                     print('[INFO] Raise the Alarm(1)')\n",
    "#                                     ini_patience_frame_counter = 1\n",
    "#                                     final_patience_frame_counter = 0\n",
    "#                                     self.flag_patience = False\n",
    "                                \n",
    "#                                 final_patience_frame_counter += 1\n",
    "#                                 patience_difference = int(final_patience_frame_counter - ini_patience_frame_counter)\n",
    "                            \n",
    "#                                 if (patience_difference >= (self.patience * self.cap_rate)):\n",
    "#                                     print('[INFO] Raise the Alarm(2)...')\n",
    "#                                     final_patience_frame_counter = 0\n",
    "                                \n",
    "#                         else: \n",
    "#                             print('Entered Else.....!!!!')\n",
    "#                             self.flag_thresh = True\n",
    "#                             self.flag_patience = True\n",
    "                                \n",
    "#                 if (len(boxes) == 0):\n",
    "#                     print('New Condition Initiated')\n",
    "#                     self.flag_thresh = True\n",
    "#                     self.flag_patience = True\n",
    "    \n",
    "#                         ###################################################\n",
    "                        \n",
    "#                 # elapsed_time = time.time() - starting_time\n",
    "#                 # fps=frame_id/elapsed_time\n",
    "#                 # cv2.putText(frame,\"FPS:\"+str(round(fps,2)),(10,50),font,2,(0,0,0),1)\n",
    "                \n",
    "                cv2.imshow(\"Image\",frame)\n",
    "                \n",
    "                key = cv2.waitKey(1)\n",
    "                if key == 27: #esc key stops qthe process\n",
    "                    break\n",
    "                \n",
    "            ################################\n",
    "            # Frame counter reinitialization\n",
    "            ################################\n",
    "            \n",
    "            if frame_counter == condition: \n",
    "                frame_counter = 0\n",
    "                \n",
    "            frame_counter = frame_counter + 1\n",
    "            \n",
    "            ################################\n",
    "                \n",
    "                \n",
    "            # ################################\n",
    "            # # Old Frame counter reinitialization\n",
    "            # ################################\n",
    "                \n",
    "            # last_highest_multiple = (self.frame_rate // self.cap_rate) * self.cap_rate\n",
    "            \n",
    "            # if frame_counter == last_highest_multiple: \n",
    "            #     frame_counter = 0\n",
    "                \n",
    "            # frame_counter = frame_counter + 1\n",
    "            \n",
    "            # ################################\n",
    "            \n",
    "            print('[INFO] Out of loop...')\n",
    "            \n",
    "        cap.release()    \n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    a =  CaptureRate('./yolo_files/yolov3.cfg.txt', './yolo_files/yolov3.weights', \n",
    "                                       './yolo_files/coco.names.txt', 0, patience = 2)\n",
    "    a.main_run()      \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
